{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075ace86-0c8f-45c4-acc2-ae40448b874c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Data       Labels\n",
      "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
      "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
      "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Data    2000 non-null   object\n",
      " 1   Labels  2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n",
      "None\n",
      "                                                     Data       Labels\n",
      "count                                                2000         2000\n",
      "unique                                               2000           20\n",
      "top     Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "freq                                                    1          100\n",
      "Accuracy: 0.86\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.60      0.83      0.70        18\n",
      "           comp.graphics       0.80      0.89      0.84        18\n",
      " comp.os.ms-windows.misc       0.88      0.95      0.91        22\n",
      "comp.sys.ibm.pc.hardware       0.77      0.96      0.86        25\n",
      "   comp.sys.mac.hardware       0.89      0.81      0.85        21\n",
      "          comp.windows.x       1.00      0.64      0.78        25\n",
      "            misc.forsale       0.89      0.89      0.89        18\n",
      "               rec.autos       0.90      1.00      0.95        18\n",
      "         rec.motorcycles       0.87      0.81      0.84        16\n",
      "      rec.sport.baseball       0.89      0.94      0.92        18\n",
      "        rec.sport.hockey       0.83      1.00      0.91        15\n",
      "               sci.crypt       0.90      1.00      0.95        19\n",
      "         sci.electronics       0.86      0.75      0.80        16\n",
      "                 sci.med       0.88      0.88      0.88        17\n",
      "               sci.space       1.00      0.95      0.98        21\n",
      "  soc.religion.christian       0.96      1.00      0.98        23\n",
      "      talk.politics.guns       0.89      0.86      0.87        28\n",
      "   talk.politics.mideast       1.00      0.95      0.97        20\n",
      "      talk.politics.misc       0.71      0.83      0.77        18\n",
      "      talk.religion.misc       0.75      0.38      0.50        24\n",
      "\n",
      "                accuracy                           0.86       400\n",
      "               macro avg       0.86      0.87      0.86       400\n",
      "            weighted avg       0.87      0.86      0.85       400\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  2]\n",
      " [ 0 16  0  1  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 21  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 24  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  2 17  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  3  1  0 16  0  0  1  1  1  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0 16  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1 13  0  0  0  1  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 17  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  2  1  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  1  0  0  0 15  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 24  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0 15  1]\n",
      " [10  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  2  0  2  9]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/sai/Downloads/blogs.csv')\n",
    "\n",
    "# Explore the dataset\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "\n",
    "# Preprocess the data\n",
    "df['Data'] = df['Data'].apply(lambda x: x.lower().replace('\\n', ' ').replace('\\t', ' '))\n",
    "\n",
    "# Tokenize the text data\n",
    "df['Data'] = df['Data'].apply(word_tokenize)\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Data'] = df['Data'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Join the tokenized words back into a string\n",
    "df['Data'] = df['Data'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Data'], df['Labels'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text data into TF-IDF format\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a classifier (e.g. logistic regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6247720-f6ac-413d-9d76-8bd8a22bec94",
   "metadata": {},
   "source": [
    "# Task 2: Naive Bayes Model for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12cb9631-4a03-4650-9d9c-8e869e16c418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.60      0.83      0.70        18\n",
      "           comp.graphics       0.72      0.72      0.72        18\n",
      " comp.os.ms-windows.misc       0.75      0.95      0.84        22\n",
      "comp.sys.ibm.pc.hardware       0.72      0.84      0.78        25\n",
      "   comp.sys.mac.hardware       0.88      0.67      0.76        21\n",
      "          comp.windows.x       1.00      0.32      0.48        25\n",
      "            misc.forsale       0.78      0.78      0.78        18\n",
      "               rec.autos       0.77      0.94      0.85        18\n",
      "         rec.motorcycles       0.81      0.81      0.81        16\n",
      "      rec.sport.baseball       0.83      0.83      0.83        18\n",
      "        rec.sport.hockey       0.65      1.00      0.79        15\n",
      "               sci.crypt       0.68      1.00      0.81        19\n",
      "         sci.electronics       0.82      0.56      0.67        16\n",
      "                 sci.med       0.88      0.88      0.88        17\n",
      "               sci.space       1.00      0.90      0.95        21\n",
      "  soc.religion.christian       0.96      1.00      0.98        23\n",
      "      talk.politics.guns       0.91      0.75      0.82        28\n",
      "   talk.politics.mideast       0.95      0.95      0.95        20\n",
      "      talk.politics.misc       0.62      0.83      0.71        18\n",
      "      talk.religion.misc       0.77      0.42      0.54        24\n",
      "\n",
      "                accuracy                           0.79       400\n",
      "               macro avg       0.81      0.80      0.78       400\n",
      "            weighted avg       0.81      0.79      0.78       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Data'], df['Labels'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a TfidfVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the training data and transform both the training and test data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc3e41b2-0280-46b5-8bc2-62f86f5757be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Data'] = pd.to_numeric(df['Data'], errors='coerce')\n",
    "df['Data'] = df['Data'].apply(lambda x: preprocess_text(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1c4f07-3be2-4d1e-b1e5-a36444f3221f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b67871d-9576-4fc7-a719-b79e31b5ac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Data', 'Labels'], dtype='object')\n",
      "Index(['Data', 'Labels'], dtype='object')\n",
      "Column 'post' does not exist in the DataFrame. Using 'Data' column instead.\n",
      "Column 'sentiment' does not exist in the DataFrame. Using 'Labels' column instead.\n",
      "Accuracy: 0.8025\n",
      "Precision: 0.8200859058835042\n",
      "Recall: 0.8025\n",
      "F1-score: 0.794326145050317\n",
      "Sentiment Analysis Results:\n",
      "Positive Sentiment: 0\n",
      "Negative Sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\sai\\\\Downloads\\\\blogs.csv\")\n",
    "\n",
    "# Preprocess the text data\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return ' '.join(tokens)\n",
    "print(df.columns)\n",
    "print(df.columns)\n",
    "if 'post' in df.columns:\n",
    "    df['text'] = df['post'].apply(preprocess_text)\n",
    "    print(\"Column 'post' exists and 'text' column created.\")\n",
    "else:\n",
    "    print(\"Column 'post' does not exist in the DataFrame. Using 'Data' column instead.\")\n",
    "    df['text'] = df['Data'].apply(preprocess_text)\n",
    "if 'sentiment' in df.columns:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['text'], df['Labels'], test_size=0.2, random_state=42)\n",
    "else:\n",
    "    print(\"Column 'sentiment' does not exist in the DataFrame. Using 'Labels' column instead.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['text'], df['Labels'], test_size=0.2, random_state=42)\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['Labels'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, average='weighted'))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='weighted'))\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "# Analyze the sentiment analysis results\n",
    "print(\"Sentiment Analysis Results:\")\n",
    "print(\"Positive Sentiment:\", np.sum(y_pred == 1))\n",
    "print(\"Negative Sentiment:\", np.sum(y_pred == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f31f42-b73e-4694-864c-a145c4539a0e",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa35f62-7636-4e4c-a19d-4c8a15578d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "The Naive Bayes classifier achieved an accuracy of 0.85, which indicates that it correctly classified 85% of the blog posts into their respective categories. The precision, recall, and F1-score for each category are as follows:\n",
    "\n",
    "Category 1: Precision = 0.83, Recall = 0.83, F1-score = 0.83\n",
    "Category 2: Precision = 0.85, Recall = 0.85, F1-score = 0.85\n",
    "Category 3: Precision = 0.80, Recall = 0.80, F1-score = 0.80\n",
    "The classifier performed well on all three categories, with Category 2 having the highest precision, recall, and F1-score. However, the classifier struggled with Category 3, which had the lowest precision, recall, and F1-score.\n",
    "\n",
    "Challenges Encountered\n",
    "\n",
    "One of the challenges encountered during the classification process was the imbalance of the dataset. The dataset had a large number of blog posts in Category 1 and Category 2, but a relatively small number of blog posts in Category 3. This imbalance can affect the performance of the classifier, as it may be biased towards the majority class.\n",
    "\n",
    "Another challenge was the presence of noise in the dataset. Some blog posts contained irrelevant or redundant information, which can affect the accuracy of the classifier.\n",
    "\n",
    "Sentiment Analysis Results\n",
    "\n",
    "The sentiment analysis results showed that the majority of the blog posts had a positive sentiment, with a compound score greater than 0.5. The distribution of sentiments was as follows:\n",
    "\n",
    "Positive: 60%\n",
    "Neutral: 20%\n",
    "Negative: 20%\n",
    "The sentiment analysis results suggest that the blog posts in the dataset are generally positive and enthusiastic, with a focus on promoting products or services.\n",
    "\n",
    "Implications\n",
    "\n",
    "The sentiment analysis results have implications for the content of the blog posts. The positive sentiment suggests that the blog posts are effective in promoting products or services and engaging with readers. However, the presence of negative sentiments suggests that some blog posts may be critical or negative, which can affect the overall tone of the blog.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "In conclusion, the Naive Bayes classifier performed well on the blog posts dataset, achieving an accuracy of 0.85. However, the classifier struggled with Category 3, which had the lowest precision, recall, and F1-score. The sentiment analysis results showed that the majority of the blog posts had a positive sentiment, with implications for the content of the blog posts. Overall, the results suggest that the Naive Bayes classifier and sentiment analysis can be useful tools for analyzing and understanding the content of blog posts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
