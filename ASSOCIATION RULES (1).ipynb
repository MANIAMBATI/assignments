{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c47e39c-c689-41e1-86dd-409513c75b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Columns:\n",
      "Index(['shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil'], dtype='object')\n",
      "Number of columns in dataset: 1\n",
      "Column Names and Data Types:\n",
      "shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil    object\n",
      "dtype: object\n",
      "Column Names:\n",
      "Index(['shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil'], dtype='object')\n",
      "First few rows of the dataset:\n",
      "  shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil\n",
      "0                             burgers,meatballs,eggs                                                                                                                                                                             \n",
      "1                                            chutney                                                                                                                                                                             \n",
      "2                                     turkey,avocado                                                                                                                                                                             \n",
      "3  mineral water,milk,energy bar,whole wheat rice...                                                                                                                                                                             \n",
      "4                                     low fat yogurt                                                                                                                                                                             \n",
      "Required columns are not present in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sai\\OneDrive\\Desktop\\Online retail.csv.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Print the current columns and their count\n",
    "print(\"Current Columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Check the number of columns\n",
    "print(f\"Number of columns in dataset: {len(df.columns)}\")\n",
    "\n",
    "# If the columns are not as expected, check the column names manually\n",
    "print(\"Column Names and Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Rename columns if necessary, based on actual data\n",
    "# Here, print actual columns to decide on renaming\n",
    "print(\"Column Names:\")\n",
    "print(df.columns)\n",
    "\n",
    "# If expected columns are not present, use actual column names found\n",
    "# Assuming the dataset actually has columns named 'InvoiceNo', 'StockCode', 'Description', and 'Quantity'\n",
    "# Adjust the names if they are different\n",
    "expected_columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity']\n",
    "\n",
    "# Rename columns if they do not match expected names\n",
    "# For demonstration, let's print the first few rows to understand the data structure\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check if columns exist and rename if necessary\n",
    "# For simplicity, let's assume you manually identify the column names\n",
    "\n",
    "# Example adjustment\n",
    "# df.columns = ['InvoiceNo', 'StockCode', 'Description', 'Quantity']\n",
    "\n",
    "# Proceed with preprocessing only if columns exist\n",
    "if all(col in df.columns for col in expected_columns):\n",
    "    # Drop rows with missing values in 'InvoiceNo', 'StockCode', or 'Description'\n",
    "    df.dropna(subset=['InvoiceNo', 'StockCode', 'Description'], inplace=True)\n",
    "    \n",
    "    # Convert 'InvoiceNo' and 'StockCode' to string type\n",
    "    df['InvoiceNo'] = df['InvoiceNo'].astype(str)\n",
    "    df['StockCode'] = df['StockCode'].astype(str)\n",
    "    \n",
    "    # Remove duplicate rows\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Remove cancelled orders (InvoiceNo starting with 'C')\n",
    "    df = df[~df['InvoiceNo'].str.startswith('C')]\n",
    "    \n",
    "    # Create basket matrix\n",
    "    basket = df.groupby(['InvoiceNo', 'Description'])['Quantity'].sum().unstack().reset_index().fillna(0).set_index('InvoiceNo')\n",
    "    \n",
    "    # Convert quantities to 1 (purchased) or 0 (not purchased)\n",
    "    basket = basket.applymap(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Print the first few rows of the basket matrix\n",
    "    print(\"First few rows of the basket matrix:\")\n",
    "    print(basket.head())\n",
    "    \n",
    "    # Apply the Apriori algorithm\n",
    "    frequent_itemsets = apriori(basket, min_support=0.01, use_colnames=True)\n",
    "    print(\"Frequent Itemsets:\")\n",
    "    print(frequent_itemsets.head())\n",
    "    \n",
    "    # Generate association rules\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "    print(\"Association Rules:\")\n",
    "    print(rules.head())\n",
    "    \n",
    "    # Analysis and Interpretation\n",
    "    print(\"Summary of Association Rules:\")\n",
    "    print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].sort_values(by='lift', ascending=False))\n",
    "    \n",
    "    # Example Insights\n",
    "    print(\"\\nInsights:\")\n",
    "    for index, row in rules.iterrows():\n",
    "        antecedent = list(row['antecedents'])\n",
    "        consequent = list(row['consequents'])\n",
    "        print(f\"If a customer buys {', '.join(antecedent)}, they are {row['confidence']*100:.2f}% likely to also buy {', '.join(consequent)}. Lift: {row['lift']:.2f}\")\n",
    "else:\n",
    "    print(\"Required columns are not present in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2b49132-4062-451f-a908-f8b2dd4d6773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['shrimp,almonds,avocado,vegetables mix,green grapes,whole weat flour,yams,cottage cheese,energy drink,tomato juice,low fat yogurt,green tea,honey,salad,mineral water,salmon,antioxydant juice,frozen smoothie,spinach,olive oil'], dtype='object')\n",
      "Columns 'InvoiceNo' and 'StockCode' do not exist\n",
      "Cannot apply Apriori algorithm because binary DataFrame does not exist\n",
      "Cannot generate association rules because frequent itemsets do not exist\n",
      "Cannot perform analysis and interpretation because rules do not exist\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\sai\\OneDrive\\Documents\\Online retail.xlsx\"\n",
    "online_retail_data = pd.read_excel(file_path)\n",
    "\n",
    "# Check column names\n",
    "print(online_retail_data.columns)\n",
    "\n",
    "# Data Preprocessing\n",
    "online_retail_data.dropna(inplace=True)\n",
    "online_retail_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Check if 'InvoiceNo' and 'StockCode' exist\n",
    "if 'InvoiceNo' in online_retail_data.columns and 'StockCode' in online_retail_data.columns:\n",
    "    # Create a binary DataFrame\n",
    "    binary_df = online_retail_data.groupby('InvoiceNo')['StockCode'].apply(lambda x: pd.Series(1, index=x)).unstack().fillna(0).astype(bool).astype(int)\n",
    "else:\n",
    "    print(\"Columns 'InvoiceNo' and 'StockCode' do not exist\")\n",
    "\n",
    "# Apply Apriori algorithm\n",
    "if 'binary_df' in locals():\n",
    "    frequent_itemsets = apriori(binary_df, min_support=0.01, use_colnames=True)\n",
    "else:\n",
    "    print(\"Cannot apply Apriori algorithm because binary DataFrame does not exist\")\n",
    "\n",
    "# Generate association rules\n",
    "if 'frequent_itemsets' in locals():\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "else:\n",
    "    print(\"Cannot generate association rules because frequent itemsets do not exist\")\n",
    "\n",
    "# Analysis and Interpretation\n",
    "if 'rules' in locals():\n",
    "    print(\"Association Rules:\")\n",
    "    print(rules.head())\n",
    "    print(\"Summary of Association Rules:\")\n",
    "    print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']].sort_values(by='lift', ascending=False))\n",
    "\n",
    "    print(\"\\nInsights:\")\n",
    "    for index, row in rules.iterrows():\n",
    "        antecedent = list(row['antecedents'])\n",
    "        consequent = list(row['consequents'])\n",
    "        print(f\"If a customer buys {', '.join(antecedent)}, they are {row['confidence']*100:.2f}% likely to also buy {', '.join(consequent)}. Lift: {row['lift']:.2f}\")\n",
    "else:\n",
    "    print(\"Cannot perform analysis and interpretation because rules do not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe80196e-a115-43d2-b561-6b5de5b78c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
